# VCFtools tutorial on how to find SNPs https://www.ddocent.com/filtering/

#filtering the vcf file, 

vcftools --gzvcf raw.vcf.gz --max-missing 0.5 --mac 3 --minQ 30 --recode --recode-INFO-all --out raw.g5mac3

# so we called vcftools, gave it a vcf file, --max-missing 0.5 = keep only variants that have been successfully genotypes in 50% of individuals
# --mac 3 = minor allele count of 3; --minQ 30 = minimum quality score or 30 ; --record-INFO-all keeps all the info flags from the old vcf file in the new one
# and --out is the name of the output file
# this removed about half of data

# filter for minimum depth for a gentype call
vcftools --vcf raw.g5mac3.recode.vcf --minDP 3 --recode --recode-INFO-all --out raw.g5mac3dp3 
# --minDP record genotypes that have less than 3 reads

# filter out indivduals that didn't sequence well
vcftools --vcf raw.g5mac3dp3.recode.vcf --missing-indv

# this creates an output called out.imiss
cat out.imiss

# some are missing up to 99% of data
# look at histogram
mawk '!/IN/' out.imiss | cut -f5 > totalmissing
gnuplot << \EOF 
set terminal dumb size 120, 30
set autoscale 
unset label
set title "Histogram of % missing data per individual"
set ylabel "Number of Occurrences"
set xlabel "% of missing data"
#set yr [0:100000]
binwidth=0.01
bin(x,width)=width*floor(x/width) + binwidth/2.0
plot 'totalmissing' using (bin($1,binwidth)):(1.0) smooth freq with boxes
pause -1
EOF

# most have individuals are missing less than 50% of data
# create list of indiv with more than 50% missing
mawk '$5 > 0.5' out.imiss | cut -f1 > lowDP.indv

# now with list, add that to the VCFtools filtering step
vcftools --vcf raw.g5mac3dp3.recode.vcf --remove lowDP.indv --recode --recode-INFO-all --out raw.g5mac3dplm

# so now that removed 9 individuals

# now restrict the data to variants called in a high percentage of individuals and fiter by mean depth of genotypes
vcftools --vcf raw.g5mac3dplm.recode.vcf --max-missing 0.95 --maf 0.05 --recode --recode-INFO-all --out DP3g95maf05 --min-meanDP 20
# this applied a genotype rate across individuals (95%) - do this by population when there at muliple localities
# so we need a file to define localities (make one from metadata) tutorial has one made
cat popmap

# now create two lists that have that have just he individual names for each pop
mawk '$2 == "BR"' popmap > 1.keep && mawk '$2 == "WL"' popmap > 2.keep

# next use VCFtools to estimate missing data for loci in each pop
vcftools --vcf DP3g95maf05.recode.vcf --keep 1.keep --missing-site --out 1
vcftools --vcf DP3g95maf05.recode.vcf --keep 2.keep --missing-site --out 2 

# look at output
head -3 1.lmiss

# combine the two files and make a list of loci about the threshold of 10% missing data to remove
cat 1.lmiss 2.lmiss | mawk '!/CHR/' | mawk '$6 > 0.1' | cut -f1,2 >> badloci

# get back into VCFtools to remove any of the loci
vcftools --vcf DP3g95maf05.recode.vcf --exclude-positions badloci --recode --recode-INFO-all --out DP3g95p5maf05


######################################
## From this point on the filtering steps assume the VCF file was generated by FreeBayes
## similar SNP callers can be configured to include the similar notations

#take a look at the info
mawk '/#/' DP3g95maf05.recode.vcf

# first filter will be on allele balance
vcffilter
# check usage
vcffilter -s -f "AB > 0.25 & AB < 0.75 | AB < 0.01" DP3g95p5maf05.recode.vcf > DP3g95p5maf05.fil1.vcf
# this filtered out loci with an allele balance below 0.25 and above 0.75, however it does
# not include those that are close to zero. It catches loci that are fixed variants
# (all indiv homozygous for one variant) -s applies it to sites not just alleles
# now view how many using mawk
mawk '!/#/' DP3g95p5maf05.recode.vcf | wc -l
# original 12754
mawk '!/#/' DP3g95p5maf05.fil1.vcf | wc -l
# now 9678

# next filter out sites that have reads on both strands
# unless we are using super small or really long fragments the SNP should be only covered by either F or R
vcffilter -f "SAF / SAR > 100 & SRF / SRR > 100 | SAR / SAF > 100 & SRR / SRF > 100" -s DP3g95p5maf05.fil1.vcf > DP3g95p5maf05.fil2.vcf

mawk '!/#/' DP3g95p5maf05.fil2.vcf | wc -l
# now 9491

# SAMtools allows to visualize alignments right from terminal
samtools tview BR_006-RG.bam reference.fasta -p E28188_L151

# so that was fun, looks like there are over two haplotypes here

# next look at the ratio of mapping qualities between reference and alternate alleles
vcffilter -f "MQM / MQMR > 0.9 & MQM / MQMR < 1.05" DP3g95p5maf05.fil2.vcf > DP3g95p5maf05.fil3.vcf

# now look at it again
samtools tview BR_004-RG.bam reference.fasta -p E20_L173

# filter for discrepancy in properly paired status of for reads supporting reference or alt alleles 
vcffilter -f "PAIRED > 0.05 & PAIREDR > 0.05 & PAIREDR / PAIRED < 1.75 & PAIREDR / PAIRED > 0.25 | PAIRED < 0.05 & PAIREDR < 0.05" -s DP3g95p5maf05.fil3.vcf > DP3g95p5maf05.fil4.vcf

# some loci will only have unpaired reads mapping to them 
mawk '!/#/' DP3g95p5maf05.fil4.vcf | wc -l

# read depth and quality are related, so filter out for low quality <1/4 of depth
vcffilter -f "QUAL / DP > 0.25" DP3g95p5maf05.fil4.vcf > DP3g95p5maf05.fil5.vcf

# now other filter occurs in steps
# first create list of depth at each locus
cut -f8 DP3g95p5maf05.fil5.vcf | grep -oe "DP=[0-9]*" | sed -s 's/DP=//g' > DP3g95p5maf05.fil5.DEPTH

# second creat list of quality scores
mawk '!/#/' DP3g95p5maf05.fil5.vcf | cut -f1,2,6 > DP3g95p5maf05.fil5.vcf.loci.qual

# third calculate mean depth
mawk '{ sum += $1; n++ } END { if (n > 0) print sum / n; }' DP3g95p5maf05.fil5.DEPTH

# fourth calc the mean plus 3X the square of mean
python3 -c "print (int(1952+3*(1952**0.5)))"

# fifth paste depth and quality files together and find loci abive the cutoff that don't have qual score = 2X depth
paste DP3g95p5maf05.fil5.vcf.loci.qual DP3g95p5maf05.fil5.DEPTH | mawk -v x=2084 '$4 > x' | mawk '$3 < 2 * $4' > DP3g95p5maf05.fil5.lowQDloci

# now remove those sites and recalc depth across loci
vcftools --vcf DP3g95p5maf05.fil5.vcf --site-depth --exclude-positions DP3g95p5maf05.fil5.lowQDloci --out DP3g95p5maf05.fil5

# take output and cut it to only the depth scores
cut -f3 DP3g95p5maf05.fil5.ldepth > DP3g95p5maf05.fil5.site.depth

# calc average depth by dividing the file by the number of individuals (31) 
mawk '!/D/' DP3g95p5maf05.fil5.site.depth | mawk -v x=31 '{print $1/x}' > meandepthpersite

# plot the data as a histogram again
gnuplot << \EOF 
set terminal dumb size 120, 30
set autoscale
set xrange [10:150] 
unset label
set title "Histogram of mean depth per site"
set ylabel "Number of Occurrences"
set xlabel "Mean Depth"
binwidth=1
bin(x,width)=width*floor(x/width) + binwidth/2.0
set xtics 5
plot 'meandepthpersite' using (bin($1,binwidth)):(1.0) smooth freq with boxes
pause -1
EOF

# loci with high read depth indicate either paralogs or multicopy loci, either way
# we want to remove them, so here we remove loci above a mean depth of 102.5
vcftools --vcf  DP3g95p5maf05.fil5.vcf --recode-INFO-all --out DP3g95p5maf05.FIL --max-meanDP 102.5 --exclude-positions DP3g95p5maf05.fil5.lowQDloci --recode 

# This script will automatically filter a FreeBayes generated VCF file using criteria related to site depth,
# quality versus depth, strand representation, allelic balance at heterzygous individuals, and paired read representation.
# The script assumes that loci and individuals with low call rates (or depth) have already been removed.

curl -L -O https://github.com/jpuritz/dDocent/raw/master/scripts/dDocent_filters
chmod +x dDocent_filters
./dDocent_filters

# apply HWE filter to remove erroneous variant calls applied by population not across all
curl -L -O https://github.com/jpuritz/dDocent/raw/master/scripts/filter_hwe_by_pop.pl
chmod +x filter_hwe_by_pop.pl

# filter our SNPs by population specific HWE - convert variant calls to SNPs - 
# will decompose complex variant calls into phased SNP and INDEL genotypes and keep the INFO flags for loci and genotypes. 
vcfallelicprimitives DP3g95p5maf05.FIL.recode.vcf --keep-info --keep-geno > DP3g95p5maf05.prim.vcf

# Remove indels
vcftools --vcf DP3g95p5maf05.prim.vcf --remove-indels --recode --recode-INFO-all --out SNP.DP3g95p5maf05

# now SNPs are in the new VCF and we can apply the HWE filter
./filter_hwe_by_pop.pl -v SNP.DP3g95p5maf05.recode.vcf -p popmap -o SNP.DP3g95p5maf05.HWE -h 0.01
# Note, I would not normally use such a high -h value. Itâ€™s purely for this example. 
# Typically, errors would have a low p-value and would be present in many populations.

# we now have confidence through all the filtering in these SNP calls
# this script will take VCF file of SNPs and parse them through BAM files looking to link SNPs into 
# haplotypes along paired reads
curl -L -O https://raw.githubusercontent.com/chollenbeck/rad_haplotyper/master/rad_haplotyper.pl
chmod +x rad_haplotyper.pl
# to run the actual script:
# #rad_haplotyper.pl -v SNP.DP3g95p5maf05.HWE.recode.vcf -x 40 -mp 1 -u 20 -ml 4 -n -r reference.fasta
# it requires a BAM file to proceed

# create list of loci to filter based on that
grep FILTERED stats.out | mawk '!/Complex/' | cut -f1 > loci.to.remove

# parse through VCF file and remove the bad RAD loci
curl -L -O https://github.com/jpuritz/dDocent/raw/master/scripts/remove.bad.hap.loci.sh
chmod +x remove.bad.hap.loci.sh
./remove.bad.hap.loci.sh loci.to.remove SNP.DP3g95p5maf05.HWE.recode.vcf 

# produce the FINAL filtered VCF file
mawk '!/#/' SNP.DP3g95p5maf05.HWE.filtered.vcf | wc -l

# how many possible errors
./ErrorCount.sh SNP.DP3g95p5maf05.HWE.filtered.vcf